{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOtYk6lJeb/txNIrbxhtFZO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dario66/Deep-Learning/blob/main/Fruit360Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "from keras.datasets import fashion_mnist # carica il Fashion-MNIST dataset\n",
        "import tensorflow as tf\n",
        "from torchsummary import summary\n",
        "from sklearn.model_selection import KFold\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import LSTM,Dense, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, Y=%s' % (trainX.shape, trainY.shape))\n",
        "print('Test: X=%s, Y=%s' % (testX.shape, testY.shape))\n",
        "\n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "    # load dataset\n",
        "    ((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
        "    # reshape dataset to have a single channel\n",
        "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "    print (len(trainX))\n",
        "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "    print (len(testX))\n",
        "    # one hot encode target values\n",
        "    trainY = tf.keras.utils.to_categorical(trainY)\n",
        "    testY = tf.keras.utils.to_categorical(testY)\n",
        "    return (trainX, trainY, testX, testY)\n",
        " \n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\n",
        "\tsingleArray1=train_norm[0][0]\n",
        "\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\n",
        "\tsingleArray1=train_norm[0][0]\n",
        "\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = tf.keras.Sequential()\n",
        "\tmodel.add(Conv2D(32, (5, 5), padding='same',activation='relu', kernel_initializer='he_uniform',input_shape=(28, 28, 1)))\n",
        "\t#numero di parametri 640 --> 3^2*1*64=576+64\n",
        "\t#output del layer Conv--->(28-3+2*0/1)+1=26x26x64\n",
        "\tmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
        "\tmodel.add(Conv2D(64, (5, 5),padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2)))\n",
        "\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t#model.summary()\n",
        "\t# compile model\n",
        "\topt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# define cnn model\n",
        "def define_model2():\n",
        "\tmodel2 = tf.keras.Sequential()\n",
        "\tmodel2.add(Conv2D(32,(5,5), strides=(1,1),input_shape=(28,28,1),padding='same',activation='relu'))\n",
        "\tmodel2.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\tmodel2.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "\tmodel2.add(Conv2D(64,(5,5), strides=(1,1), padding='same' ))\n",
        "\tmodel2.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\tmodel2.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
        "\tmodel2.add(Flatten())\n",
        "\tmodel2.add(Dense(1024))\n",
        "\tmodel2.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\tmodel2.add(tf.keras.layers.Dropout(0.5))\n",
        "\tmodel2.add(Dense(10, activation='softmax'))\n",
        "\tmodel2.add(tf.keras.layers.Activation(\"relu\"))\n",
        "\treturn model2\n",
        "\n",
        "\n",
        "# evaluate a model using k-fold cross-validation\n",
        "def evaluate_model(dataX, dataY, n_folds=5):\n",
        "\tscores, histories = list(), list()\n",
        "\t# prepare cross validation\n",
        "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
        "\t# enumerate splits\n",
        "\tfor train_ix, test_ix in kfold.split(dataX):\n",
        "\t\t# define model\n",
        "\t\tmodel2 = define_model2()\n",
        "\t\t# select rows for train and test\n",
        "\t\ttrainX, trainY, testX, te1stY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
        "\t\t# fit model\n",
        "\t\thistory = model2.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
        "\t\t# evaluate model\n",
        "\t\t_, acc = model2.evaluate(testX, testY, verbose=0)\n",
        "\t\tprint('> %.3f' % (acc * 100.0))\n",
        "\t\t# append scores\n",
        "\t\tscores.append(acc)\n",
        "\t\thistories.append(history)\n",
        "\treturn scores, histories\n",
        " \n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(histories):\n",
        "\tfor i in range(len(histories)):\n",
        "\t\t# plot loss\n",
        "\t\tplt.subplot(211)\n",
        "\t\tplt.title('Cross Entropy Loss')\n",
        "\t\tplt.plot(histories[i].history['loss'], color='blue', label='train')\n",
        "\t\tplt.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
        "\t\t# plot accuracy\n",
        "\t\tplt.subplot(212)\n",
        "\t\tplt.title('Classification Accuracy')\n",
        "\t\tplt.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
        "\t\tplt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
        "\tplt.show()\n",
        " \n",
        "# summarize model performance\n",
        "def summarize_performance(scores):\n",
        "\t# print summary\n",
        "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, np.std(scores)*100, len(scores)))\n",
        "\t# box and whisker plots of results\n",
        "\tplt.boxplot(scores)\n",
        "\tplt.show()\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# evaluate model\n",
        "\tscores, histories = evaluate_model(trainX, trainY)\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(histories)\n",
        "\t# summarize estimated performance\n",
        "\tsummarize_performance(scores)\n",
        "# example of loading the fashion mnist dataset\n",
        "\n",
        "def show_prova():\n",
        " (trainX, trainy), (testX, testy) = fashion_mnist.load_data()\n",
        " # summarize loaded dataset\n",
        " print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
        " print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
        " # plot first few images\n",
        " for i in range(9):\n",
        "\t # define subplot\n",
        "\t plt.subplot(330 + 1 + i)\n",
        "\t # plot raw pixel data\n",
        "\t plt.imshow(trainX[i], cmap=plt.get_cmap('gray'))\n",
        " # show the figure\n",
        " plt.show() \n",
        "\n",
        "# entry point, run the test harness\n",
        "#show_prova()\n",
        "run_test_harness()"
      ],
      "metadata": {
        "id": "lJG3ODV-5cdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the deep model on the test dataset\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import load_model\n",
        "\n",
        " \n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "\t# reshape dataset to have a single channel\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\t# one hot encode target values\n",
        "\ttrainY = tf.keras.utils.to_categorical(trainY)\n",
        "\ttestY = tf.keras.utils.to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        " \n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# load model\n",
        "\tmodel = load_model('final_model.h5')\n",
        "\t# evaluate model on test dataset\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6twclJ4vG8l",
        "outputId": "65245bfd-ffb7-402b-a4a2-7ad882bafd43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> 91.580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the final model to file\n",
        "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "from keras.datasets import fashion_mnist # carica il Fashion-MNIST dataset\n",
        "import tensorflow as tf\n",
        "from torchsummary import summary\n",
        "from sklearn.model_selection import KFold\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import LSTM,Dense, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "\t# reshape dataset to have a single channel\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\t# one hot encode target values\n",
        "\ttrainY = tf.keras.utils.to_categorical(trainY)\n",
        "\ttestY = tf.keras.utils.to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        " \n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = tf.keras.Sequential()\n",
        "\tmodel.add(Conv2D(64, (3, 3), padding='same',activation='relu', kernel_initializer='he_uniform',input_shape=(28, 28, 1)))\n",
        "\t#numero di parametri 640 --> 3^2*1*64=576+64\n",
        "\t#output del layer Conv--->(28-3+2*0/1)+1=26x26x64\n",
        "\tmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3),strides=(2, 2)))\n",
        "\tmodel.add(Conv2D(64, (3, 3),padding='same', activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t#model.summary()\n",
        "\t# compile model\n",
        "\topt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# fit model\n",
        "\tmodel.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)\n",
        "\t# save model\n",
        "\tmodel.save('final_model.h5')\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "metadata": {
        "id": "8q3T5TGZzVwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e93dc4-39e5-4cd9-f7a8-c0f6500875a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "26435584/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "from keras.datasets import fashion_mnist # carica il Fashion-MNIST dataset\n",
        "import tensorflow as tf\n",
        "from torchsummary import summary\n",
        "from sklearn.model_selection import KFold\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import LSTM,Dense, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        " \n",
        "# load and prepare the image\n",
        "def load_image(filename):\n",
        "\t# load the image\n",
        "\timg = tf.keras.utils.load_img(filename, color_mode = \"grayscale\", target_size=(28, 28))\n",
        "\t# convert to array\n",
        "\timg = tf.keras.utils.img_to_array(img)\n",
        "\t# reshape into a single sample with 1 channel\n",
        "\timg = img.reshape(1, 28, 28, 1)\n",
        "\t# prepare pixel data\n",
        "\timg = img.astype('float32')\n",
        "\timg = img / 255.0\n",
        "\treturn img\n",
        " \n",
        "# load an image and predict the class\n",
        "def run_example():\n",
        "\t# load the image\n",
        "\timg = load_image('uno.png')\n",
        "\t# load model\n",
        "\tmodel = tf.keras.models.load_model('final_model.h5')\n",
        "\t# predict the class\n",
        "\tresult = model.predict(img)\n",
        "\tprint(result[0])\n",
        " \n",
        "# entry point, run the example\n",
        "run_example()"
      ],
      "metadata": {
        "id": "Hh-x7nc54NWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d moltean/fruits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz23_9JSG9Cx",
        "outputId": "e6537361-21ac-4097-f4f8-99d726227960"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fruits.zip to /content\n",
            " 99% 1.27G/1.28G [00:05<00:00, 191MB/s]\n",
            "100% 1.28G/1.28G [00:05<00:00, 231MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip fruits.zip"
      ],
      "metadata": {
        "id": "uQNRJGYsHWEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "import tensorflow as tf\n",
        "from torchsummary import summary\n",
        "from sklearn.model_selection import KFold\n",
        "from statistics import mean\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import LSTM,Dense, Flatten\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import random\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "#super useful\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "def load_dataset(path):\n",
        "    data=load_files(path)\n",
        "    files = np.array(data['filenames'])\n",
        "    targets = np.array(data['target'])\n",
        "    target_labels = np.array(data['target_names'])\n",
        "    return files, targets, target_labels\n",
        "\n",
        "X_train, y_train, target_labels = load_dataset('fruits-360_dataset/fruits-360/Training')\n",
        "\n",
        "X_test, y_test, _ = load_dataset('fruits-360_dataset/fruits-360/Test')\n",
        "\n",
        "#numero di classi presenti\n",
        "className = glob('fruits-360_dataset/fruits-360/Training' + '/*')\n",
        "n_class = len(className)\n",
        "print('numero di classi:'+ str(n_class))\n",
        "\n",
        "y_train=np_utils.to_categorical(y_train, n_class)\n",
        "y_test=np_utils.to_categorical(y_test, n_class)\n",
        "\n",
        "#funzione per convertire i dati in array\n",
        "def convert_to_array(pics):\n",
        "    img_arr =[]\n",
        "    for pic in pics:\n",
        "        img_arr.append(np.asarray(load_img(pic)))\n",
        "    return img_arr\n",
        "\n",
        "X_train = np.array(convert_to_array(X_train))\n",
        "X_test = np.array(convert_to_array(X_test))\n",
        "\n",
        "#X_train = X_train.astype('float32')/255\n",
        "#X_test = X_test.astype('float32')/255\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYcGDc8hIXPp",
        "outputId": "ba3d12be-4bc2-411c-ec27-09feb4bf8c94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numero di classi:131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ywfPLpS-e5G3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
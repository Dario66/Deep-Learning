{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectFruit360Dario.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOOrTLq8JKgTG6rmeUIDvhv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dario66/Deep-Learning/blob/main/ProjectFruit360Dario.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G7crOkTp_KE",
        "outputId": "22d8f337-6a12-4d66-983a-7141950212a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.63.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d moltean/fruits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvJYgVLxqLmf",
        "outputId": "0bcb9297-bc91-4741-9bca-1ca212bf577b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fruits.zip to /content\n",
            " 99% 1.27G/1.28G [00:06<00:00, 208MB/s]\n",
            "100% 1.28G/1.28G [00:06<00:00, 211MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip fruits.zip"
      ],
      "metadata": {
        "id": "JS_CWRp9q1MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "import tensorflow as tf\n",
        "from torchsummary import summary\n",
        "from sklearn.model_selection import KFold\n",
        "from statistics import mean\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import LSTM,Dense, Flatten\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import random\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n"
      ],
      "metadata": {
        "id": "KX_QgInAqlhe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path,name):\n",
        "    print('['+str(name)+']Path: '+str(path))\n",
        "    data=load_files(path)\n",
        "    for key, value in data.items():\n",
        "      print(key, value)\n",
        "    files = np.array(data['filenames'])\n",
        "    targets = np.array(data['target'])\n",
        "    target_labels = np.array(data['target_names'])\n",
        "    return files, targets, target_labels\n",
        "\n",
        "\n",
        "#funzione per convertire i dati in array\n",
        "def convert_to_array(pics):\n",
        "    img_arr =[]\n",
        "    for pic in pics:\n",
        "        img_arr.append(np.asarray(load_img(pic)))\n",
        "    return img_arr\n"
      ],
      "metadata": {
        "id": "0Tl1zDRgqrQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path_to_train = 'fruits-360_dataset/fruits-360/Training'\n",
        "path_to_test = 'fruits-360_dataset/fruits-360/Test'\n",
        "\n",
        "Generator = ImageDataGenerator()\n",
        "train_data = Generator.flow_from_directory(path_to_train, (100, 100),\n",
        "                                           shuffle=True, class_mode='categorical',color_mode='rgb')\n",
        "test_data = Generator.flow_from_directory(path_to_test, (100, 100),\n",
        "                                          shuffle=True, class_mode='categorical',color_mode='rgb')\n",
        "\n",
        "\n",
        "#X_train, y_train, target_labels = load_dataset('fruits-360_dataset/fruits-360/Training','Train')\n",
        "#print(X_train.size,y_train.size,target_labels.size)\n",
        "#X_test, y_test, _ = load_dataset('fruits-360_dataset/fruits-360/Test','Test')\n",
        "\n",
        "#numero di classi presenti\n",
        "#className = glob('fruits-360_dataset/fruits-360/Training' + '/*')\n",
        "#n_class = len(className)\n",
        "#print('numero di classi:'+ str(n_class))\n",
        "\n",
        "#y_train=np_utils.to_categorical(y_train, n_class)\n",
        "#y_test=np_utils.to_categorical(y_test, n_class)\n",
        "\n",
        "#X_train = np.array(convert_to_array(X_train))\n",
        "#X_test = np.array(convert_to_array(X_test))\n",
        "\n",
        "#X_train = X_train.astype('float32')/255\n",
        "#X_test = X_test.astype('float32')/255\n",
        "\n",
        "\n",
        "#print(str(X_train[0][0][0]))\n",
        "#X_train.shape"
      ],
      "metadata": {
        "id": "OgMkLimkquUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9466e27c-6b53-468c-f3a1-620fad7362c0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 67692 images belonging to 131 classes.\n",
            "Found 22688 images belonging to 131 classes.\n"
          ]
        }
      ]
    }
  ]
}
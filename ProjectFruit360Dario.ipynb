{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectFruit360Dario.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPbn0fREQYwAGAQjZNXadg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dario66/Deep-Learning/blob/main/ProjectFruit360Dario.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installo Kaggle"
      ],
      "metadata": {
        "id": "nyzyAJAGA05u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G7crOkTp_KE",
        "outputId": "9c5718f0-0f5f-4ea5-8a87-a6f09db77231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.63.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scarico il Fruits 360 dataset"
      ],
      "metadata": {
        "id": "hI7R6a_kA-R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d moltean/fruits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvJYgVLxqLmf",
        "outputId": "3793504f-5e16-40ca-d933-3e7113846154"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fruits.zip to /content\n",
            "100% 1.28G/1.28G [00:07<00:00, 199MB/s]\n",
            "100% 1.28G/1.28G [00:07<00:00, 180MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estraggo lo zip e elimino il file"
      ],
      "metadata": {
        "id": "g_Ia83nZBCTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip fruits.zip\n",
        "\n",
        "! rm fruits.zip"
      ],
      "metadata": {
        "id": "JS_CWRp9q1MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importo le librerie necessarie"
      ],
      "metadata": {
        "id": "zRbFU4y2BIj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.normalization.batch_normalization import BatchNormalization \n",
        "import tensorflow as tf\n",
        "from torchsummary import summary\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from statistics import mean\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import random\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Input, LSTM\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n",
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "import cv2\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "KX_QgInAqlhe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stampo i 75 frutti con numero maggiore di esemplari"
      ],
      "metadata": {
        "id": "L0zdQDpQBNxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_train = 'fruits-360_dataset/fruits-360/Training'\n",
        "path_to_test = 'fruits-360_dataset/fruits-360/Test'\n",
        "#numero di campioni per ogni frutto\n",
        "fruits = []\n",
        "fruits_image = []\n",
        "for i in os.listdir(path_to_train):\n",
        "    for image_filename in os.listdir(path_to_train+'/' + i):\n",
        "        fruits.append(i) \n",
        "        fruits_image.append(i + '/' + image_filename)\n",
        "newData = Counter(fruits)\n",
        "frequent_fruits = newData.most_common(30)\n",
        "frequent_fruits\n",
        "\n"
      ],
      "metadata": {
        "id": "7HUu8d3cfm7g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7226e1bc-5302-4156-ceb6-8e7b9abc6d4a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Grape Blue', 984),\n",
              " ('Plum 3', 900),\n",
              " ('Cherry 2', 738),\n",
              " ('Strawberry Wedge', 738),\n",
              " ('Cherry Rainier', 738),\n",
              " ('Tomato 1', 738),\n",
              " ('Melon Piel de Sapo', 738),\n",
              " ('Peach 2', 738),\n",
              " ('Tomato 3', 738),\n",
              " ('Walnut', 735),\n",
              " ('Pear Stone', 711),\n",
              " ('Cauliflower', 702),\n",
              " ('Fig', 702),\n",
              " ('Pear Forelle', 702),\n",
              " ('Pepper Orange', 702),\n",
              " ('Pear 2', 696),\n",
              " ('Tomato Heart', 684),\n",
              " ('Apple Red Yellow 2', 672),\n",
              " ('Tomato 2', 672),\n",
              " ('Pepper Red', 666),\n",
              " ('Pear Red', 666),\n",
              " ('Pepper Yellow', 666),\n",
              " ('Nut Forest', 654),\n",
              " ('Nut Pecan', 534),\n",
              " ('Pineapple Mini', 493),\n",
              " ('Cherry 1', 492),\n",
              " ('Grape White 3', 492),\n",
              " ('Mulberry', 492),\n",
              " ('Grapefruit White', 492),\n",
              " ('Apple Golden 2', 492)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elimino le cartelle delle classi che non vogliamo utilizzare nel nostro set di train e test"
      ],
      "metadata": {
        "id": "LnoyoTmZBXAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from inspect import EndOfBlock\n",
        "import shutil\n",
        "for filename in os.listdir(\"fruits-360_dataset/fruits-360/Training\"):\n",
        "    f = os.path.join(\"fruits-360_dataset/fruits-360/Training/\", filename)\n",
        "    # checking if it is a filec\n",
        "    #if os.path.isdir(f):\n",
        "    d = dict(frequent_fruits)\n",
        "    #print(list1)\n",
        "    #for key in d:\n",
        "       #print(key)\n",
        "    if filename in d:\n",
        "       #print(filename)\n",
        "       #print(filename)\n",
        "       continue\n",
        "     \n",
        "    #print(filename)\n",
        "    shutil.rmtree(\"fruits-360_dataset/fruits-360/Training/\"+str(filename), ignore_errors=False, onerror=None)\n",
        "    shutil.rmtree(\"fruits-360_dataset/fruits-360/Test/\"+str(filename), ignore_errors=False, onerror=None)\n",
        "    #print(f)\n",
        "       #os.remove(filename) \n",
        "       #os.remove(f) \n",
        "\n",
        "#os.rmdir(\"fruits-360_dataset/fruits-360/Training/Clementine\")    "
      ],
      "metadata": {
        "id": "ywgoz-SEOFEJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.normalization.batch_normalization import BatchNormalization\n",
        "import tensorflow as tf\n",
        "from torchsummary import summary\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from statistics import mean\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import random\n",
        "import seaborn as sns\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Input, LSTM, Rescaling\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n",
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "import cv2\n",
        "from keras.models import Model\n",
        "import pathlib\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import regularizers\n",
        "from keras.layers import RandomFlip, RandomRotation, RandomZoom\n",
        "# We can also use the history (that we saved before) to check the behavior of the training.\n",
        "# history is a Python dictionary that cointains the values of the behavior of the loss\n",
        "# during training (one value for each epoch).\n",
        "def display_history(history):\n",
        "    mse_training = history.history['loss']\n",
        "    acc_training = history.history['accuracy']\n",
        "\n",
        "    mse_val = history.history['val_loss']\n",
        "    acc_val = history.history['val_accuracy']\n",
        "\n",
        "    # Visualize the behavior of the loss\n",
        "    plt.plot(mse_training)\n",
        "    plt.plot(mse_val)\n",
        "    plt.grid()\n",
        "    plt.title('Loss during training')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.show()\n",
        "\n",
        "    # and of the accuracy\n",
        "    plt.plot(acc_training)\n",
        "    plt.plot(acc_val)\n",
        "    plt.grid()\n",
        "    plt.title('Accuracy during training')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "path_to_train = 'fruits-360_dataset/fruits-360/Training'\n",
        "path_to_test = 'fruits-360_dataset/fruits-360/Test'\n",
        "\n",
        "\n",
        "data_dir = pathlib.Path(path_to_test)\n",
        "\n",
        "batch_size = 32\n",
        "epoch=10\n",
        "d1 = 100\n",
        "d2 = 100\n",
        "\n",
        "\n",
        "\n",
        "validation_steps = 14145//batch_size # if you have validation data \n",
        "validation_steps=110\n",
        "\n",
        "\n",
        "seed = 42\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  path_to_train,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=seed,\n",
        "  image_size=(d1, d2),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  path_to_test,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=seed,\n",
        "  image_size=(d1, d2),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "#steps_per_epoch = len(list(train_ds))//batch_size\n",
        "\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)\n",
        "num_classes = len(class_names)\n",
        "print ('Numero di Label:'+str(num_classes))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "data_augmentation = lambda input_shape: tf.keras.Sequential([\n",
        "    RandomFlip(\"horizontal\", input_shape=input_shape),\n",
        "    RandomRotation(0.1),\n",
        "    RandomZoom(0.1),\n",
        "  ]\n",
        ")\n",
        "\n",
        "def get_model(input_shape):\n",
        "    x = Input(shape=input_shape)\n",
        "    #augmented = (data_augmentation(input_shape))(x)\n",
        "\n",
        "    #r = Rescaling(1./255)(augmented)\n",
        "    r = Rescaling(1./255)(x)\n",
        "    c1 = Conv2D(16, 3, padding='same', activation='relu')(r)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "    c2 = Conv2D(32, 3, padding='same', activation='relu')(p1)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    c3 = Conv2D(64, 3, padding='same', activation='relu')(p2)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    d = Dropout(.2)(p3)\n",
        "    f = Flatten()(d)\n",
        "    d1 = Dense(128, activation='relu')(f)\n",
        "    d2 = Dense(num_classes)(d1)\n",
        "\n",
        "\n",
        "    model = Model(x, d2)\n",
        "\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "callback = EarlyStopping(monitor=\"val_accuracy\",\n",
        "    mode = \"max\",\n",
        "    min_delta=0.001,\n",
        "    patience=3,\n",
        "    restore_best_weights=True)\n",
        "#, callbacks = [callback]\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "accepted_diff = 0.01\n",
        "def linear_regression_equality(y_true, y_pred):\n",
        "    diff = K.abs(y_true-y_pred)\n",
        "    return K.mean(K.cast(diff < accepted_diff, tf.float32))\n",
        "\n",
        "model = get_model((d1, d2, 3))\n",
        "\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=loss_fn, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(train_ds, epochs=epoch, validation_data = validation_ds, callbacks = [callback])\n",
        "\n",
        "score=model.evaluate(validation_ds)\n",
        "score\n",
        "print(f\"Model Accuracy: %{score[1]*100}\")\n",
        "\n",
        "np.save('my_history.npy',history.history)\n",
        "display_history(history)"
      ],
      "metadata": {
        "id": "o8-dJd_0mrD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323fc55b-59c8-4454-bd4b-8b0535daad3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20167 files belonging to 30 classes.\n",
            "Using 16134 files for training.\n",
            "Found 6725 files belonging to 30 classes.\n",
            "Using 1345 files for validation.\n",
            "['Apple Golden 2', 'Apple Red Yellow 2', 'Cauliflower', 'Cherry 1', 'Cherry 2', 'Cherry Rainier', 'Fig', 'Grape Blue', 'Grape White 3', 'Grapefruit White', 'Melon Piel de Sapo', 'Mulberry', 'Nut Forest', 'Nut Pecan', 'Peach 2', 'Pear 2', 'Pear Forelle', 'Pear Red', 'Pear Stone', 'Pepper Orange', 'Pepper Red', 'Pepper Yellow', 'Pineapple Mini', 'Plum 3', 'Strawberry Wedge', 'Tomato 1', 'Tomato 2', 'Tomato 3', 'Tomato Heart', 'Walnut']\n",
            "Numero di Label:30\n",
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " rescaling_15 (Rescaling)    (None, 100, 100, 3)       0         \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 100, 100, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_45 (MaxPoolin  (None, 50, 50, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 50, 50, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_46 (MaxPoolin  (None, 25, 25, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 25, 25, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_47 (MaxPoolin  (None, 12, 12, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 128)               1179776   \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 30)                3870      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,207,230\n",
            "Trainable params: 1,207,230\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "505/505 [==============================] - 170s 335ms/step - loss: 0.3274 - accuracy: 0.9046 - val_loss: 0.0655 - val_accuracy: 0.9822\n",
            "Epoch 2/10\n",
            "505/505 [==============================] - 168s 333ms/step - loss: 0.0204 - accuracy: 0.9950 - val_loss: 0.0500 - val_accuracy: 0.9888\n",
            "Epoch 3/10\n",
            "505/505 [==============================] - 173s 342ms/step - loss: 7.1015e-04 - accuracy: 0.9999 - val_loss: 0.0686 - val_accuracy: 0.9829\n",
            "Epoch 4/10\n",
            "505/505 [==============================] - 174s 343ms/step - loss: 9.5058e-05 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9836\n",
            "Epoch 5/10\n",
            " 73/505 [===>..........................] - ETA: 2:21 - loss: 6.9926e-05 - accuracy: 1.0000"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_train = 'fruits-360_dataset/fruits-360/Training'\n",
        "path_to_test = 'fruits-360_dataset/fruits-360/Test'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        path_to_train,\n",
        "        target_size=(100, 100),\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        path_to_test,\n",
        "        target_size=(100, 100),\n",
        "        class_mode='categorical')\n",
        "\n",
        "\n",
        "train_generator.image_shape[0]\n",
        "test_generator.image_shape[0]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,(3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64,(3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5)) # helps prevent overfitting\n",
        "model.add(Dense(131)) # output\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "              optimizer = \"adam\",\n",
        "              metrics = [\"accuracy\"])\n",
        "\n",
        "callback = EarlyStopping(monitor='val_loss', patience=10, verbose=2)\n",
        "\n",
        "learning_model=model.fit(train_generator,steps_per_epoch=50,epochs=30,validation_data=test_generator,validation_steps=25,callbacks=callback)\n",
        "\n",
        "learning_model.history.keys()\n",
        "\n",
        "score=learning_model.model.evaluate(test_generator)\n",
        "score\n",
        "print(f\"Model Accuracy: %{score[1]*100}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9k_3952fAx77"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}